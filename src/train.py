import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import mlflow
import mlflow.sklearn
import sys
import os

# --- CONFIGURATION ---
# On d√©finit une graine al√©atoire pour que les r√©sultats soient reproductibles
np.random.seed(42)

def generate_data():
    """
    G√©n√®re un dataset factice de qualit√© de vin pour l'exemple.
    Dans un vrai projet, on chargerait un CSV (ex: pd.read_csv('data/wine.csv'))
    """
    print("üîÑ G√©n√©ration des donn√©es...")
    # 1000 lignes, 10 colonnes (features)
    X = np.random.rand(1000, 10) 
    # La cible (y) est une fonction des features + un peu de bruit al√©atoire
    y = X[:, 0] * 2 + X[:, 1] * 5 + np.random.normal(0, 0.1, 1000)
    
    # On cr√©e un DataFrame pour faire propre
    cols = [f"feature_{i}" for i in range(10)]
    df = pd.DataFrame(X, columns=cols)
    df['quality'] = y
    
    # Sauvegarde locale pour DVC (simulation)
    os.makedirs("data", exist_ok=True)
    df.to_csv("data/wine_quality.csv", index=False)
    return df

def train_model():
    """
    Fonction principale : Charge les donn√©es, entra√Æne le mod√®le et log dans MLflow.
    """
    print("üöÄ D√©marrage de l'entra√Ænement...")

    # 1. Chargement des donn√©es
    df = generate_data()
    X = df.drop("quality", axis=1)
    y = df["quality"]

    # 2. S√©paration train/test (80% train, 20% test)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    # 3. Configuration des hyperparam√®tres du mod√®le
    # On pourrait les passer en arguments du script pour l'optimisation
    n_estimators = 100
    max_depth = 5

    # 4. Activation de MLflow
    # On d√©finit l'exp√©rience (le dossier virtuel dans MLflow)
    mlflow.set_experiment("WineQuality_Industrial_Ops")

    with mlflow.start_run():
        print("ü§ñ Entra√Ænement du mod√®le Random Forest...")
        rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth)
        rf.fit(X_train, y_train)

        # 5. Pr√©dictions et Calcul des m√©triques
        predictions = rf.predict(X_test)
        rmse = np.sqrt(mean_squared_error(y_test, predictions))
        mae = mean_absolute_error(y_test, predictions)

        print(f"üìä M√©triques -> RMSE: {rmse:.4f}, MAE: {mae:.4f}")

        # 6. LOGGING DANS MLFLOW (Crucial pour le MLOps)
        # On enregistre les param√®tres utilis√©s (pour savoir quelle config a donn√© quel r√©sultat)
        mlflow.log_param("n_estimators", n_estimators)
        mlflow.log_param("max_depth", max_depth)
        
        # On enregistre les m√©triques de performance
        mlflow.log_metric("rmse", rmse)
        mlflow.log_metric("mae", mae)

        # On enregistre le mod√®le lui-m√™me pour pouvoir le d√©ployer plus tard
        # "model" est le nom du dossier dans le registre
        mlflow.sklearn.log_model(rf, "model")
        
        # Condition de succ√®s (pour le pipeline CI/CD)
        # Si le mod√®le est trop mauvais, on peut faire √©chouer le script
        if rmse > 0.5:
            print("‚ùå Mod√®le rejet√© : RMSE trop √©lev√©")
            # sys.exit(1) # D√©commenter pour bloquer le d√©ploiement si mauvais
        else:
            print("‚úÖ Mod√®le valid√©")

if __name__ == "__main__":
    train_model()